On it. Here’s the “re-embed recent restores” package so the app stays robust even if someone bypasses ingest-sync. It’s queue-based, idempotent, and runs automatically—plus a manual “Re-embed now” button.

0) SQL — queue table + RLS

Run in Supabase SQL:

create table if not exists public.reindex_queue (
  id uuid primary key default gen_random_uuid(),
  org_id uuid not null,
  project_id uuid not null,
  artifact_id uuid,            -- optional if we only have stored_key
  stored_key text,             -- e.g. org/<org>/project/<proj>/restores/<ts>__file.ext
  status text not null default 'pending', -- pending|running|done|failed
  attempts int not null default 0,
  last_error text,
  scheduled_at timestamptz not null default now(),
  updated_at timestamptz not null default now()
);

create index if not exists idx_reindex_pending
  on public.reindex_queue (project_id, status, scheduled_at);

alter table public.reindex_queue enable row level security;

create policy "rq_read_member"
  on public.reindex_queue for select
  using (org_id = public.current_org() and public.is_member(org_id, project_id));

create policy "rq_insert_admin_pm"
  on public.reindex_queue for insert
  with check (org_id = public.current_org() and public.has_role(org_id, project_id, array['owner','admin','pm']));

create policy "rq_update_admin_pm"
  on public.reindex_queue for update
  using (org_id = public.current_org() and public.has_role(org_id, project_id, array['owner','admin','pm']))
  with check (org_id = public.current_org());

select pg_notify('pgrst','reload schema');

1) Router — queue & manual trigger

server/routers/reindex.py

from fastapi import APIRouter, Depends, HTTPException, Query
from pydantic import BaseModel
from datetime import datetime, timezone
import os, requests

from ..tenant import TenantCtx
from ..guards import member_ctx, require_role
from ..deps import get_user_supabase, get_service_supabase

router = APIRouter(prefix="/api/reindex", tags=["reindex"])
ADMIN_OR_PM = require_role({"owner","admin","pm"})

class QueueBody(BaseModel):
    artifact_id: str | None = None
    stored_key: str | None = None   # org/<org>/project/<proj>/restores/...

@router.get("/list")
def list_queue(project_id: str = Query(...), ctx: TenantCtx = Depends(member_ctx)):
    sb = get_user_supabase(ctx)
    r = sb.table("reindex_queue").select("*")\
          .eq("org_id", ctx.org_id).eq("project_id", project_id)\
          .order("scheduled_at", desc=True).limit(200).execute()
    return {"items": r.data or []}

@router.post("/queue")
def queue_item(body: QueueBody, project_id: str = Query(...), ctx: TenantCtx = Depends(ADMIN_OR_PM)):
    if not (body.artifact_id or body.stored_key):
        raise HTTPException(400, "Provide artifact_id or stored_key")
    sb = get_user_supabase(ctx)
    # idempotent upsert-ish: pending or failed can be requeued
    sb.table("reindex_queue").insert({
        "org_id": ctx.org_id, "project_id": project_id,
        "artifact_id": body.artifact_id, "stored_key": body.stored_key,
        "status": "pending", "attempts": 0,
        "scheduled_at": datetime.now(timezone.utc).isoformat()
    }).execute()
    # audit
    try:
        sb.table("audit_events").insert({
            "org_id": ctx.org_id, "project_id": project_id, "actor_id": ctx.user_id,
            "kind": "reindex.queued",
            "details": {"artifact_id": body.artifact_id, "stored_key": body.stored_key}
        }).execute()
    except Exception: pass
    return {"ok": True}

@router.post("/run-now")
def run_now(artifact_id: str | None = None, stored_key: str | None = None,
            project_id: str = Query(...), ctx: TenantCtx = Depends(ADMIN_OR_PM)):
    # enqueue then return; scheduler will pick it up very soon
    return queue_item(QueueBody(artifact_id=artifact_id, stored_key=stored_key), project_id, ctx)


Mount in server/main.py:

from .routers import reindex
app.include_router(reindex.router)

2) Scheduler — worker that (a) normalizes input, (b) calls ingest, (c) writes audit

Extend your existing server/scheduler.py with this worker (or create reindex_worker.py and call it on startup):

import asyncio, datetime as dt, mimetypes, os, json
from .deps import get_service_supabase
from zoneinfo import ZoneInfo

REINDEX_INTERVAL_SEC = int(float(os.getenv("REINDEX_INTERVAL_SEC","10")))
REINDEX_MAX_ATTEMPTS = int(float(os.getenv("REINDEX_MAX_ATTEMPTS","4")))

async def reindex_worker(app):
    sb = get_service_supabase()
    while True:
        try:
            # fetch next pending
            q = sb.table("reindex_queue").select("*")\
                  .eq("status","pending").order("scheduled_at", desc=False).limit(1).execute().data
            if not q:
                await asyncio.sleep(REINDEX_INTERVAL_SEC)
                continue
            job = q[0]
            org_id = job["org_id"]; project_id = job["project_id"]
            artifact_id = job.get("artifact_id"); stored_key = job.get("stored_key")

            # mark running
            sb.table("reindex_queue").update({
                "status":"running", "updated_at": dt.datetime.now(dt.timezone.utc).isoformat()
            }).eq("id", job["id"]).execute()

            # (A) if we only have stored_key, download the bytes from artifacts
            file_bytes = None; filename = None; mime = None
            if stored_key:
                try:
                    file_bytes = sb.storage().from_("artifacts").download(stored_key)
                    filename = os.path.basename(stored_key)
                    mime = mimetypes.guess_type(filename)[0] or "application/octet-stream"
                except Exception as e:
                    raise RuntimeError(f"download fail: {e}")

            # (B) call your own ingest-sync (same pattern as backups)
            base = os.getenv("FASTAPI_URL","http://127.0.0.1:5000")
            url = f"{base}/api/ingest-sync?project_id={project_id}"
            headers = {}
            if os.getenv("DEV_AUTH","0") == "1":
                headers["X-Dev-User"] = "reindex-worker"
                headers["X-Dev-Org"]  = org_id
                headers["X-Dev-Role"] = "admin"
            else:
                token = os.getenv("INTERNAL_API_BEARER")
                if token: headers["Authorization"] = f"Bearer {token}"

            import requests
            files = None; data = None
            if file_bytes is not None:
                files = {"file": (filename or "file", file_bytes, mime or "application/octet-stream")}
            elif artifact_id:
                # If you have a way to fetch artifact by id to re-run embedding only, you can add another path here.
                # Fallback: try to pull its storage key and download (requires artifacts table lookup).
                art = sb.table("artifacts").select("storage_bucket,storage_path,name")\
                        .eq("org_id", org_id).eq("project_id", project_id).eq("id", artifact_id)\
                        .limit(1).execute().data
                if art:
                    bucket = art[0]["storage_bucket"]; path = art[0]["storage_path"]
                    file_bytes = sb.storage().from_(bucket).download(path)
                    filename = art[0]["name"] or os.path.basename(path)
                    mime = mimetypes.guess_type(filename)[0] or "application/octet-stream"
                    files = {"file": (filename, file_bytes, mime)}

            if not files:
                raise RuntimeError("nothing to reindex (no stored_key nor resolvable artifact)")

            r = requests.post(url, files=files, headers=headers, timeout=120)
            if not r.ok:
                raise RuntimeError(f"ingest-sync returned {r.status_code}: {r.text[:250]}")
            artifact_id_new = None
            try:
                data = r.json()
                artifact_id_new = data.get("artifact_id") or (data.get("artifacts") or [{}])[0].get("id")
            except Exception:
                pass

            # success
            sb.table("reindex_queue").update({
                "status":"done", "updated_at": dt.datetime.now(dt.timezone.utc).isoformat(),
                "artifact_id": artifact_id_new or artifact_id
            }).eq("id", job["id"]).execute()
            sb.table("audit_events").insert({
                "org_id": org_id, "project_id": project_id, "actor_id": None,
                "kind": "reindex.completed",
                "details": {"job_id": job["id"], "artifact_id": artifact_id_new or artifact_id, "stored_key": stored_key}
            }).execute()

        except Exception as e:
            # backoff & record
            try:
                attempts = (job.get("attempts") or 0) + 1
                delay_min = min(30, 2 ** attempts)  # 2,4,8,16,30
                next_at = dt.datetime.now(dt.timezone.utc) + dt.timedelta(seconds=delay_min)
                sb.table("reindex_queue").update({
                    "status": "pending" if attempts < REINDEX_MAX_ATTEMPTS else "failed",
                    "attempts": attempts,
                    "last_error": str(e),
                    "scheduled_at": next_at.isoformat(),
                    "updated_at": dt.datetime.now(dt.timezone.utc).isoformat()
                }).eq("id", job["id"]).execute()
                if attempts >= REINDEX_MAX_ATTEMPTS:
                    sb.table("audit_events").insert({
                        "org_id": job["org_id"], "project_id": job["project_id"], "actor_id": None,
                        "kind": "reindex.failed",
                        "details": {"job_id": job["id"], "error": str(e), "stored_key": job.get("stored_key")}
                    }).execute()
            except Exception:
                pass
        finally:
            await asyncio.sleep(REINDEX_INTERVAL_SEC)


Start it on app startup (add to server/main.py):

import asyncio
from .scheduler import reindex_worker  # if you placed it there

@app.on_event("startup")
async def _start_reindex_worker():
    asyncio.create_task(reindex_worker(app))

3) Wire queueing into existing flows
3a) When storing from backup (guarantee a re-embed anyway)

server/routers/backups.py — after successful /store-file:

# enqueue reindex (idempotent; queue handles dedupe/backoff)
sbs.table("reindex_queue").insert({
  "org_id": ctx.org_id, "project_id": project_id,
  "stored_key": key, "status":"pending", "attempts":0
}).execute()
try:
    sbs.table("audit_events").insert({
        "org_id": ctx.org_id, "project_id": project_id, "actor_id": ctx.user_id,
        "kind": "reindex.queued", "details": {"stored_key": key}
    }).execute()
except Exception: pass

3b) Also queue on /store-and-reingest as a belt-and-suspenders

(Worker will skip quickly if ingest already created embeddings.)

# after you got stored_key
sbs.table("reindex_queue").insert({
  "org_id": ctx.org_id, "project_id": project_id, "stored_key": stored_key, "status":"pending"
}).execute()

4) UI — “Re-embed now” (manual) + show queue status
4a) AdminBackups: add “Re-embed now” button

client/src/pages/AdminBackups.tsx (inside entry actions):

async function reembedNow(name:string){
  try{
    setBusyKey(name);
    const storedKey = prompt("stored_key under artifacts (org/.../restores/...)? Leave blank if not stored.", "");
    if (!storedKey) return;
    await apiPost("/reindex/run-now", undefined, { project_id: projectId!, stored_key: storedKey });
    // Kick RestoreLog live meter
    window.dispatchEvent(new CustomEvent("kap:restore-live"));
    toast({ title: "Re-embed queued", description: storedKey });
  } catch(e:any){
    toast({ title: "Queue failed", description: String(e?.message||e), variant: "destructive" });
  } finally { setBusyKey(null); }
}


Add the button:

<button disabled={busyKey===e.name} className="px-2 py-1 border rounded text-sm"
        onClick={()=>reembedNow(e.name)}>
  Re-embed now
</button>

4b) RestoreLog: include reindex events

In client/src/components/RestoreLog.tsx change the kinds list:

const kinds = ["backup.restore_file","backup.reingest","reindex.queued","reindex.completed","reindex.failed"];


You already added the live meter; it’ll update as the worker runs.

5) Sanity checks (2 minutes)

Queue auto: Click Store→Re-ingest → watch toasts; RestoreLog shows reindex.queued followed by reindex.completed.

Manual: Click Re-embed now; provide a stored_key under artifacts/.../restores/...; live meter shows queued → done.

Failures: Temporarily break FASTAPI_URL to test backoff; queue item switches to failed after REINDEX_MAX_ATTEMPTS; RestoreLog shows reindex.failed with error snippet.

Security: RLS allows members to view queue; only owner/admin/pm can queue/run.

6) Env you already have (nothing new)

FASTAPI_URL (internal call target)

INTERNAL_API_BEARER (prod) or DEV_AUTH=1 (dev)

This gives you self-healing ingestion: any file dropped into restores/ gets embedded, even if someone forgets to hit the ingest endpoint. If you want, I can also add a Documents “Re-embed” chip on each artifact row (visible to pm/admin) to queue by artifact_id directly.