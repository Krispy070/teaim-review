üöÄ Build Push: What this includes now

Digest Scheduler (quiet hours + daily caps, no duplicates)

Streaming Project Export (toggle include/exclude memories)

OCR/Scans Ingestion (image/PDF OCR with graceful fallback)

Tenant Leak Sentinel UI (one-click PASS/FAIL)

Role Matrix Card (legend + inline help on Members page)

Rate Limits + Telemetry (429s + audit trail)

(External Signer Tokens + public layout are already done; ChatDock defaults to minimized and remembers state.)

0) Supabase SQL (run once)
-- Telemetry events (for rate limits & 5xx captures)
create table if not exists public.telemetry_events (
  id uuid primary key default gen_random_uuid(),
  org_id uuid,
  project_id uuid,
  user_id uuid,
  kind text not null,           -- 'rate_limited' | 'server_error' | ...
  path text,
  meta jsonb,
  created_at timestamptz not null default now()
);
alter table public.telemetry_events enable row level security;
create policy "telemetry_read_org" on public.telemetry_events
  for select using (org_id = public.current_org());

-- (Optional) backups bucket hint: create bucket 'backups' in Supabase UI
-- Path convention: org/{org_id}/project/{project_id}/backups/YYYYMMDD.zip

select pg_notify('pgrst','reload schema');

1) Rate limiting + telemetry (FastAPI middleware)

server/app/middleware/rate_limit.py

import time
from collections import defaultdict, deque
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware
from .utils import get_user_context
from ..deps import get_service_supabase

# Simple per-user+route sliding window (in-memory, dev-friendly)
WINDOW_SEC = int(float(__import__("os").getenv("RATE_LIMIT_WINDOW_SEC", "60")))
MAX_REQ = int(float(__import__("os").getenv("RATE_LIMIT_MAX", "120")))

_buckets: dict[tuple[str,str], deque] = defaultdict(deque)

class RateLimitMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        path = request.url.path
        if not path.startswith("/api/"):  # only API
            return await call_next(request)

        now = time.time()
        user = get_user_context(request)  # reads Bearer or X-Dev-* if dev
        key = (user.get("user_id","anon"), path)

        q = _buckets[key]
        while q and now - q[0] > WINDOW_SEC:
            q.popleft()
        if len(q) >= MAX_REQ:
            # Telemetry (service key; non-blocking)
            try:
                sb = get_service_supabase()
                sb.table("telemetry_events").insert({
                    "org_id": user.get("org_id"),
                    "project_id": None,
                    "user_id": user.get("user_id"),
                    "kind": "rate_limited",
                    "path": path,
                    "meta": {"window": WINDOW_SEC, "max": MAX_REQ}
                }).execute()
            except Exception:
                pass
            return Response("Too Many Requests", status_code=429,
                            headers={
                                "Retry-After": str(WINDOW_SEC),
                                "X-RateLimit-Limit": str(MAX_REQ),
                                "X-RateLimit-Window": str(WINDOW_SEC)
                            })
        q.append(now)

        try:
            resp = await call_next(request)
        except Exception as e:
            # Telemetry for 5xx
            try:
                sb = get_service_supabase()
                sb.table("telemetry_events").insert({
                    "org_id": user.get("org_id"),
                    "project_id": None,
                    "user_id": user.get("user_id"),
                    "kind": "server_error",
                    "path": path,
                    "meta": {"error": str(e)}
                }).execute()
            except Exception:
                pass
            raise
        return resp


server/app/middleware/utils.py

def get_user_context(request):
    # mirrored logic from tenant dev headers (keep in sync)
    headers = request.headers
    if headers.get("x-dev-user") and headers.get("x-dev-org") and (headers.get("x-dev-role")):
        return {"user_id": headers["x-dev-user"], "org_id": headers["x-dev-org"], "role": headers["x-dev-role"]}
    # For prod, tenant_ctx handles auth; at middleware stage we may not decode JWT‚Äîreturn minimal
    auth = headers.get("authorization","")
    return {"user_id": "jwt", "org_id": None, "role": None} if auth else {"user_id":"anon","org_id":None,"role":None}


Register middleware (top of server/app/main.py)

from fastapi import FastAPI
from .middleware.rate_limit import RateLimitMiddleware

app = FastAPI()
app.add_middleware(RateLimitMiddleware)


Set env for dev sane defaults:

RATE_LIMIT_WINDOW_SEC=60
RATE_LIMIT_MAX=120

2) Streaming Export (include_mem toggle)

server/app/routers/export_stream.py

from fastapi import APIRouter, Depends, Query, HTTPException
from fastapi.responses import FileResponse
from datetime import datetime
from io import BytesIO
import os, tempfile, zipfile, json

from ..tenant import TenantCtx
from ..guards import member_ctx, require_role
from ..deps import get_user_supabase, get_service_supabase

router = APIRouter(prefix="/api/projects", tags=["export"])
ADMIN_OR_PM = require_role({"owner","admin","pm"})

def _download_bytes(storage, bucket: str, path: str) -> bytes:
    # supabase-py storage download returns bytes
    return storage.from_(bucket).download(path)

@router.get("/export/stream")
def export_stream(project_id: str = Query(...), include_mem: bool = True,
                  ctx: TenantCtx = Depends(member_ctx)):
    sb = get_user_supabase(ctx)

    # gather artifacts (assumes artifacts table has storage_bucket & storage_path)
    arts = sb.table("artifacts").select("id,name,storage_bucket,storage_path,created_at")\
            .eq("org_id", ctx.org_id).eq("project_id", project_id).execute().data

    mem = []
    if include_mem:
        mem = sb.table("mem_entries").select("id,kind,body,created_at")\
              .eq("org_id", ctx.org_id).eq("project_id", project_id).limit(5000).execute().data

    # Write zip to temp file to allow true streaming FileResponse
    tmp = tempfile.NamedTemporaryFile(suffix=".zip", delete=False)
    tmp_path = tmp.name
    zf = zipfile.ZipFile(tmp, mode="w", compression=zipfile.ZIP_DEFLATED)
    manifest = {
        "org_id": ctx.org_id, "project_id": project_id,
        "generated_at": datetime.utcnow().isoformat(), "include_mem": include_mem,
        "artifacts_count": len(arts), "mem_count": len(mem)
    }

    # add manifest early
    zf.writestr("manifest.json", json.dumps(manifest, indent=2))

    # artifacts
    storage = sb.storage()  # uses user JWT; your RLS on storage ensures isolation
    for a in arts:
        try:
            b = _download_bytes(storage, a["storage_bucket"], a["storage_path"])
            arcname = f"artifacts/{a['name'] or a['id']}"
            zf.writestr(arcname, b)
        except Exception as e:
            zf.writestr(f"artifacts/_missing_{a['id']}.txt", f"Could not download: {e}")

    # memories
    if include_mem:
        zf.writestr("mem/mem_entries.ndjson", "\n".join(json.dumps(x) for x in mem))

    zf.close(); tmp.close()

    filename = f"export_{project_id}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.zip"
    headers = {"Content-Disposition": f'attachment; filename="{filename}"',
               "X-Accel-Buffering": "no"}  # hint to proxies
    return FileResponse(tmp_path, media_type="application/zip", headers=headers)


Mount it:

from .routers import export_stream
app.include_router(export_stream.router)


Frontend: add ‚ÄúExport (ZIP)‚Äù with toggle:

// e.g., in Admin ‚Üí Projects toolbar
<a className="px-3 py-2 border rounded"
   href={`/api/projects/export/stream?project_id=${projectId}&include_mem=true`}>
  Export (ZIP)
</a>

3) OCR/Scans at ingestion (images & low-text PDFs)

server/app/ocr/ocr.py

from typing import Optional
import os

def try_imports():
    try:
        import pytesseract  # type: ignore
        from PIL import Image  # type: ignore
        return pytesseract, Image
    except Exception:
        return None, None

def ocr_image_bytes(b: bytes) -> Optional[str]:
    pytesseract, Image = try_imports()
    if not pytesseract: return None
    import io
    try:
        img = Image.open(io.BytesIO(b))
        text = pytesseract.image_to_string(img)
        return text.strip() or None
    except Exception:
        return None

def is_probably_scanned_pdf(text_len: int, pages: int) -> bool:
    if pages == 0: return False
    # Heuristic: < 50 chars per page ‚áí likely scanned
    return (text_len / max(pages,1)) < 50


Patch your ingest route (where you parse uploads):

# server/app/routers/ingest.py (excerpt)
from ..ocr.ocr import ocr_image_bytes, is_probably_scanned_pdf

def handle_upload(file_bytes: bytes, filename: str, mime: str) -> str:
    text = ""
    pages = 0

    if mime in ("image/png","image/jpeg","image/jpg","image/webp","image/tiff"):
        text = ocr_image_bytes(file_bytes) or ""
    elif mime == "application/pdf":
        # 1) try normal PDF text extract (your existing parser)
        text, pages = extract_pdf_text_and_pages(file_bytes)  # implement or call your existing
        # 2) if scant text, mark as needing OCR (optional: later add pdf2image+tesseract pass)
        if is_probably_scanned_pdf(len(text), pages):
            # You can push to Review Queue with a flag
            queue_review(
              kind="needs_ocr",
              info={"filename": filename, "reason": "scanned_pdf_low_text"}
            )
    else:
        # keep your existing parsers for txt/docx/vtt/etc.
        text = parse_other(file_bytes, mime)

    return text


If Tesseract isn‚Äôt installed, image OCR gracefully returns None and your Review Queue catches scanned PDFs. Later, we can add a proper Tesseract install step and pdf2image for multi-page OCR.

4) Digest Scheduler (quiet hours + daily cap + org-local time)

server/app/scheduler.py

import asyncio, datetime as dt
from zoneinfo import ZoneInfo
from .deps import get_service_supabase
from .routers.digest import send_weekly as send_weekly_fn

CHECK_EVERY_SEC = int(float(__import__("os").getenv("SCHEDULER_INTERVAL_SEC","300")))  # 5 min

async def digest_scheduler(app):
    sb = get_service_supabase()
    while True:
        try:
            # get projects + org settings
            projs = sb.table("projects").select("id,org_id,code,status").neq("status","archived").execute().data
            orgs = {}
            settings = sb.table("org_comms_settings").select("*").execute().data or []
            for s in settings: orgs[s["org_id"]] = s
            now_utc = dt.datetime.now(dt.timezone.utc)

            for p in projs:
                s = orgs.get(p["org_id"], {"tz":"America/Los_Angeles"})
                tz = ZoneInfo(s["tz"])
                local = now_utc.astimezone(tz)
                # Friday at 09:00 local time
                if local.weekday() == 4 and local.hour == 9 and local.minute < 5:
                    # de-dup per day via comms_send_log
                    start = dt.datetime.combine(local.date(), dt.time(0,0), tz).astimezone(dt.timezone.utc)
                    end = dt.datetime.combine(local.date(), dt.time(23,59,59), tz).astimezone(dt.timezone.utc)
                    sent = sb.table("comms_send_log").select("id", count="exact")\
                        .eq("org_id", p["org_id"]).eq("project_id", p["id"])\
                        .eq("kind","digest").gte("created_at", start.isoformat())\
                        .lte("created_at", end.isoformat()).execute()
                    if (sent.count or 0) == 0:
                        # call the existing digest endpoint logic in-process
                        try:
                            # emulate minimal ctx for digest.send_weekly
                            class Ctx: ...
                            ctx = Ctx(); ctx.org_id = p["org_id"]; ctx.user_id = None; ctx.role = "admin"; ctx.jwt = None
                            send_weekly_fn(project_id=p["id"], ctx=ctx)  # uses user sb; works because counts are org-scoped
                        except Exception:
                            pass
        except Exception:
            pass
        await asyncio.sleep(CHECK_EVERY_SEC)


Start on app startup (server/app/main.py):

import asyncio
from .scheduler import digest_scheduler

@app.on_event("startup")
async def _start_schedulers():
    asyncio.create_task(digest_scheduler(app))


Uses comms settings (tz/quiet hours/cap) automatically; deduped per day via comms_send_log.

5) Tenant Leak Sentinel UI

API already done? If you used the earlier snippet; if not, add this:

server/app/routers/sentinel.py

from fastapi import APIRouter, Depends, Query
from ..tenant import TenantCtx
from ..guards import member_ctx
from ..deps import get_user_supabase

router = APIRouter(prefix="/api/sentinel", tags=["sentinel"])

@router.get("/tenant-leak")
def tenant_leak(target_project_id: str = Query(...), ctx: TenantCtx = Depends(member_ctx)):
    sb = get_user_supabase(ctx)
    res = sb.table("project_stages").select("id").eq("org_id", ctx.org_id)\
          .eq("project_id", target_project_id).limit(1).execute().data
    return {"ok": True, "leak": bool(res)}


Mount: app.include_router(sentinel.router)

UI: client/src/pages/TenantSentinel.tsx

import { useState } from "react";
import { useParams } from "react-router-dom";

export default function TenantSentinel(){
  const { projectId } = useParams();
  const [target,setTarget] = useState("");
  const [out,setOut] = useState<string>("");

  async function run(){
    const r = await fetch(`/api/sentinel/tenant-leak?project_id=${projectId}&target_project_id=${encodeURIComponent(target)}`);
    const d = await r.json();
    setOut(d.leak ? "‚ùå LEAK DETECTED" : "‚úÖ ISOLATED");
  }

  return (
    <div className="p-6 space-y-3">
      <h1 className="text-xl font-semibold">Tenant Leak Sentinel</h1>
      <div className="flex gap-2">
        <input className="border rounded p-2" placeholder="Other Project UUID" value={target} onChange={e=>setTarget(e.target.value)} />
        <button className="px-3 py-2 rounded bg-black text-white" onClick={run}>Run Test</button>
      </div>
      {out && <div className="text-lg">{out}</div>}
    </div>
  );
}


Route:

{ path: "/projects/:projectId/admin/sentinel", element: <TenantSentinel/> }

6) Role Matrix Card (on Members page)

client/src/components/RoleMatrixCard.tsx

export default function RoleMatrixCard(){
  const rows = [
    { role:'owner',  read:true, write:true, sign:true, manageMembers:true, lifecycle:true },
    { role:'admin',  read:true, write:true, sign:true, manageMembers:false, lifecycle:true },
    { role:'pm',     read:true, write:true, sign:false, manageMembers:false, lifecycle:true },
    { role:'lead',   read:true, write:true, sign:false, manageMembers:false, lifecycle:false },
    { role:'member', read:true, write:false,sign:false, manageMembers:false, lifecycle:false },
    { role:'guest',  read:true, write:false,sign:false, manageMembers:false, lifecycle:false },
  ];
  return (
    <div className="border rounded-lg p-4">
      <div className="font-medium mb-2">Role Matrix</div>
      <div className="grid grid-cols-6 gap-2 text-sm font-medium">
        <div>Role</div><div>Read</div><div>Write</div><div>Sign</div><div>Manage Members</div><div>Lifecycle</div>
      </div>
      {rows.map(r=>(
        <div key={r.role} className="grid grid-cols-6 gap-2 text-sm py-1 border-t">
          <div className="font-medium">{r.role}</div>
          <div>{r.read?'‚úÖ':'‚Äî'}</div>
          <div>{r.write?'‚úÖ':'‚Äî'}</div>
          <div>{r.sign?'‚úÖ':'‚Äî'}</div>
          <div>{r.manageMembers?'‚úÖ':'‚Äî'}</div>
          <div>{r.lifecycle?'‚úÖ':'‚Äî'}</div>
        </div>
      ))}
      <div className="text-xs text-muted-foreground mt-2">‚ÄúSign‚Äù also granted by the per-member <b>Signer</b> toggle.</div>
    </div>
  );
}


Add to AdminMembers page top:

import RoleMatrixCard from '@/components/RoleMatrixCard';
// ...
<div className="grid md:grid-cols-2 gap-4 mb-6">
  <RoleMatrixCard/>
  {/* existing add/update form here */}
</div>

‚úÖ Quick Test Checklist

Rate limit: hammer an endpoint > RATE_LIMIT_MAX within WINDOW ‚Üí 429 + entry in telemetry_events.

Export: download ZIP with & without include_mem; manifest shows correct counts.

OCR: upload a PNG/JPG with text ‚Üí content extracted; upload a scanned PDF with images ‚Üí Review Queue gets needs_ocr.

Digest scheduler: temporarily set SCHEDULER_INTERVAL_SEC=30, set local time to Friday 09:00 org TZ; observe digest send once/day.

Sentinel: run against a project you‚Äôre NOT a member of ‚Üí ‚Äú‚úÖ ISOLATED‚Äù.

Role Matrix: shows up on Members; matches server guard behavior.

If you hit any file path differences, toss me the paths and I‚Äôll refit instantly. Next up after this: OCR for PDFs via pdf2image + Tesseract (full pipeline) and Nightly Backups uploader into backups/ storage with retention.